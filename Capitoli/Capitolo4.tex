% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../tesi.tex
% !TEX spellcheck = it-IT

%************************************************

%************************************************


In questo capitolo si descriverà la progettazione e l'esecuzione della sperimentazione. Si partirà pertanto dalla descrizione dati su cui quest'ultima è stata effettuata, proseguendo con la scelta delle modalità di esecuzione più interessanti e concludendo con una serie di tabelle e grafici contenenti i risultati ottenuti, opportunamente commentati.  
L'obiettivo di questa prima sperimentazione è valutare l'efficacia del sistema analizzato al fine di comprendere le cause di un eventuale successo o insuccesso delle tecniche utilizzate e quindi decidere se proseguire gli studi in questa direzione o definire strategie alternative.
Il corpus di documenti utilizzato\cite{McMinn:2013:BLC:2505515.2505695}. per testare le performance della soluzione proposta, è stato costruito proprio per la valutazione del task di event detection. Questo corpus ricopre un periodo di quattro settimane ed è composto circa 120 milioni di tweets. A partire da questi tweets, sono stati generati un pool di eventi \lq\lq candidati \rq\rq attraverso alcuni approcci dello stato dell'arte e Wikipedia. Attraverso crowdsourcing, sono stati raccolti i giudizi di rilevanza rispetto di questi eventi candidati, solo dopo aver fornito una propria definizione di evento.
Al termine di tale processo sono stati raccolti i giudizi di 150.000 tweet, suddivisi in 500 eventi.

In seguito è fornita una descrizione maggiormente dettagliata di tale dataset.
\section{Dataset per la valutazione}


Sebbene il task di event detection sia un'area molto fervida di ricerca, vi sono, ad oggi, pochi corpus disponibili per valutare le performance di un sistema su larga scala. Creare un tale corpus, a causa della srande mole di dati, richiede sia molto tempo che risorse. Inoltre, a causa dei termini di servizio di Twitter
\footnote{https//dev.twitter.com/overview/terms/agreement-and-policy: \emph{\lq\lq If you provide an API that returns Twitter data, you may only return IDs (including tweet IDs and user IDs).\rq\rq}},
 non è possibile includere in questi corpus il contenuto dei tweet, ma solo gli identificativi di questi ultimi.

Al fine di testare il sistema prodotto, è stato adoperato un corpora costruito proprio per la valutazione di sistemi
di scoperta di eventi a partire da Twitter \cite{McMinn:2013:BLC:2505515.2505695}.
In questo corpus sono stati raccolti tweets a partire dal 10/10/2012 al 7/11/2012, tramite le API streaming di Twitter.
La scelta di questo intervallo temporale non  fu casuale, ma   è motivata dal fatto che, in quel periodo, erano previsti eventi molto importanti come le elezioni presidenziali degli Stati Uniti e l'uragano Sandy.
Sono stati applicati i seguenti filtri 
\begin{itemize}
	\item \textbf{language-filter} :  sono stati filtrati solo i tweet di lingua inglese \footnote{https://code.google.com/archive/p/language-detection/}
, utilizzando una libreria java che consente una la scoperta automatica della lingua.
\item \textbf{spam-filter} : 
Al fine di rimuovere parte dello spam presente su twitter, sono state applicate le seguenti regole empiriche \cite{Benevenuto10detectingspammers}
    \begin{itemize}
	\item tweet con più di tre hashtag
	\item tweet con più di due url
	\item tweet con più di tre user-mentions
	\end{itemize}
\end{itemize}
Dopo l'applicazione di questi filtri sono stati raccolti 120 milioni di tweets.
Di questi, circa il 30\% era costituito da  \emph{retweet} (quasi 40 milioni). Poiché i retweet non sono  altro una copia di un tweet di un altro utente, i creatori del corpus non hanno incluso questi ultimi nei giudizi di rilevanza. 
\subsection{Generazione Eventi Candidati}
Gli autori del dataset, per poter raccogliere dei giudizi di rilevanza in merito ad eventi hanno innanzitutto fornito il loro concetto di evento come segue:
\begin{definizione}[Evento]
Un evento è qualcosa di \textbf{significante}  che avviene in un luogo e tempo specifico.
\end{definizione}
Rispetto alla definizione\ref{def:evento} data dal TDT, viene aggiunto il vincolo di \emph{significatività} di un evento, per scartare


piuttosto che manualmente una lista di eventi, hanno utilizzato due approcci della letteratura (\emph{detection-approach}) e Wikipedia Events Curent Portal (\emph{curated-approach}) \footnote{https://en.wikipedia.org/wiki/Portal:Current\_events}.
I sistemi di scoperta di eventi della letteratura usati sono i seguenti:
\begin{itemize}
\item l'approccio basato su LSH proposto da Petrovi\'c \cite{Petrovic:2010:SFS:1857999.1858020}
\item l'approccio basato su Cluster-Summarization proposto da Aggarwal e Subbian \cite{doi:10.1137/1.9781611972825.54}


\end{itemize}

\subsection{Raccolta dati}
Di questi 80 milioni sono stati resi pubblici, come detto in precedenza, solo gli id dei tweet e degli utenti, è necessario quindi, un ulteriore step per ritrovare il contenuto di tali tweet.
Avendo gli identificativi dei tweets, esitono due metodologie per ritovare il contenuto: le API di twitter, o attraverso un crawling di twitter.com.
Utilizzare le API di twitter fornendo come query gli id \footnote{https://dev.twitter.com/rest/reference/get/statuses/}, permette di ottenere non solo il contenuto testuale, ma anche ulteriori meta-dati come eventuali hashtag, urls, mentions, in formato JSON.
Tuttavia vi è un limite orario di 150 richieste \footnote{in ogni richiesta si possono richiedere 100 id}, quindi scaricare un corpus di grandi dimensioni, come nel nostro caso, richiederebbe troppo tempo. Per tale ragione, si è adottato un crawler fornito pubblicamente dal TREC Microblog Task \footnote{https://github.com/myleott/twitter-corpus-tools}, che consente di aggirare questo limite. A termine di questa fase di crawling sono stati raccolti circa 15 milioni di tweets, di cui  circa 10 milioni  sono retweets. Poiché i retweet non sono sati inclusi nei giudizi di rilevanza, si è deciso di scartarli in quanto non influenti per la valutazione del sistema. La maggior parte dei tweet non  ritrovati è dovuta al fatto   che  utenti che avevano pubblicato status raccolti nel corpus, hanno eliminato i loro tweets o perfino il loro profilo.



